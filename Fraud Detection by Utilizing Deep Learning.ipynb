{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobile Payments Fraud Detection Using Arificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/python/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, InputLayer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import clone_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "style.use('ggplot') # optional dark_background for dark theme\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epoch, metric='binary_accuracy'):\n",
    "    metric_title = metric.replace('_',' ').title()\n",
    "    # Plot training & validation accuracy values\n",
    "    epoch_range = range(1, epoch+1)\n",
    "    plt.plot(epoch_range, history.history[metric])\n",
    "    plt.plot(epoch_range, history.history['val_'+metric])\n",
    "    plt.title('Model '+metric_title)\n",
    "    plt.ylabel(metric_title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(epoch_range, history.history['loss'])\n",
    "    plt.plot(epoch_range, history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def print_confusion_matrix(testset,predictions):\n",
    "    conmat=pd.DataFrame(confusion_matrix(testset, predictions, labels=[1,0]),\n",
    "                        index=['Actual Fraud','Actual Non-Fraud'],\n",
    "                        columns=['Pred Fraud','Pred Non-Fraud'])\n",
    "    TP=conmat.iloc[0,0]/(conmat.iloc[0,0]+conmat.iloc[0,1])\n",
    "    FN=conmat.iloc[0,1]/(conmat.iloc[0,0]+conmat.iloc[0,1])\n",
    "    TN=conmat.iloc[1,1]/(conmat.iloc[1,0]+conmat.iloc[1,1])\n",
    "    FP=conmat.iloc[1,0]/(conmat.iloc[1,0]+conmat.iloc[1,1])\n",
    "    print('Percent of true positives: {:.2%}'.format(TP))\n",
    "    print('Percent of false negatives: {:.2%}'.format(FN))\n",
    "    print('Percent of true negatives: {:.2%}'.format(TN))\n",
    "    print('Percent of false positives: {:.2%}'.format(FP))\n",
    "    return conmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are some constant settings for all the models which our team experimented on\n",
    "batch_bin=32\n",
    "num_epochs=5\n",
    "train_pct=0.8\n",
    "validate_pct=0.2\n",
    "loss_function='binary_crossentropy'\n",
    "optimization_function='RMSProp'\n",
    "metric='binary_accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaySim EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('PS_20174392719_1491204439457_log.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "nameOrig          0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "nameDest          0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6362620 entries, 0 to 6362619\n",
      "Data columns (total 11 columns):\n",
      "step              int64\n",
      "type              object\n",
      "amount            float64\n",
      "nameOrig          object\n",
      "oldbalanceOrg     float64\n",
      "newbalanceOrig    float64\n",
      "nameDest          object\n",
      "oldbalanceDest    float64\n",
      "newbalanceDest    float64\n",
      "isFraud           int64\n",
      "isFlaggedFraud    int64\n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 534.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step                  743\n",
       "type                    5\n",
       "nameOrig          6353307\n",
       "nameDest          2722362\n",
       "isFraud                 2\n",
       "isFlaggedFraud          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['step','type','nameOrig','nameDest','isFraud','isFlaggedFraud']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CASH_IN</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>1399284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CASH_OUT</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2233384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>4116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBIT</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>41432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2151495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">TRANSFER</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>528812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   count\n",
       "type     isFraud isFlaggedFraud         \n",
       "CASH_IN  0       0               1399284\n",
       "CASH_OUT 0       0               2233384\n",
       "         1       0                  4116\n",
       "DEBIT    0       0                 41432\n",
       "PAYMENT  0       0               2151495\n",
       "TRANSFER 0       0                528812\n",
       "         1       0                  4081\n",
       "                 1                    16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['type','isFraud','isFlaggedFraud'])[['isFraud']].count().rename(columns={'isFraud':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for the categorical 'type' variable\n",
    "dummies = pd.get_dummies(data['type'])\n",
    "data2 = pd.concat([data[['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest',\n",
    "                        'isFraud']],dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data 80-20 across training and testing datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data2.loc[:,data2.columns!='isFraud'],\n",
    "                                                    data2.loc[:,data2.columns=='isFraud'],\n",
    "                                                    test_size=validate_pct,train_size=train_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale datasets using StandardScaler on the training datasets\n",
    "standard = StandardScaler()\n",
    "standard_x_train = standard.fit_transform(x_train)\n",
    "standard_x_test = standard.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale datasets using MinMaxScaler on the training datasets\n",
    "minmax = MinMaxScaler()\n",
    "minmax_x_train = minmax.fit_transform(x_train)\n",
    "minmax_x_test = minmax.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset y variable to numpy array\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1270896, 1: 1628}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many non-fraud and fraud transactions are in the test set\n",
    "unique,counts = np.unique(y_test,return_counts=True)\n",
    "dict(zip(unique,counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into non-fraud and fraud dataframes\n",
    "non_fraud = data2[data2['isFraud']==0]\n",
    "fraud = data2[data2['isFraud']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6354407, 12), (8213, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud.shape, fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8213, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud = non_fraud.sample(fraud.shape[0])\n",
    "non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>CASH_IN</th>\n",
       "      <th>CASH_OUT</th>\n",
       "      <th>DEBIT</th>\n",
       "      <th>PAYMENT</th>\n",
       "      <th>TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20128.0</td>\n",
       "      <td>20128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step   amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0     1    181.0          181.0             0.0             0.0   \n",
       "1     1    181.0          181.0             0.0         21182.0   \n",
       "2     1   2806.0         2806.0             0.0             0.0   \n",
       "3     1   2806.0         2806.0             0.0         26202.0   \n",
       "4     1  20128.0        20128.0             0.0             0.0   \n",
       "\n",
       "   newbalanceDest  isFraud  CASH_IN  CASH_OUT  DEBIT  PAYMENT  TRANSFER  \n",
       "0             0.0        1        0         0      0        0         1  \n",
       "1             0.0        1        0         1      0        0         0  \n",
       "2             0.0        1        0         0      0        0         1  \n",
       "3             0.0        1        0         1      0        0         0  \n",
       "4             0.0        1        0         0      0        0         1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_balanced_data = fraud.append(non_fraud, ignore_index=True)\n",
    "rand_balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8213\n",
       "0    8213\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_balanced_data['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a randomly balanced datasets for training and testing the feed forward neural netowrk on\n",
    "rand_x_train,rand_x_test,rand_y_train,rand_y_test=train_test_split(rand_balanced_data.loc[:,non_fraud.columns!='isFraud'],\n",
    "                                                                   rand_balanced_data.loc[:,non_fraud.columns=='isFraud'],\n",
    "                                                                   train_size=train_pct,test_size=validate_pct)\n",
    "rand_y_train=np.array(rand_y_train)\n",
    "rand_y_test=np.array(rand_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale datasets using StandardScaler on the training datasets\n",
    "rand_standard = StandardScaler()\n",
    "rand_standard_x_train = standard.fit_transform(rand_x_train)\n",
    "rand_standard_x_test = standard.transform(rand_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale datasets using MinMaxScaler on the training datasets\n",
    "rand_minmax = MinMaxScaler()\n",
    "rand_minmax_x_train = minmax.fit_transform(rand_x_train)\n",
    "rand_minmax_x_test = minmax.transform(rand_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# create a SMOTE balanced version of the standard training dataset\n",
    "standard_smt = SMOTE()\n",
    "standard_x_train_sm, standard_y_train_sm = standard_smt.fit_sample(standard_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5083511, 5083511])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(standard_y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# create a SMOTE balanced version of the standard training dataset\n",
    "minmax_smt = SMOTE()\n",
    "minmax_x_train_sm, minmax_y_train_sm = minmax_smt.fit_sample(minmax_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5083511, 5083511])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(standard_y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test-train split for the autoencoder using only non-fraud data\n",
    "x_train_ae, x_test_ae, y_train_ae, y_test_ae = train_test_split(non_fraud.loc[:,non_fraud.columns!='isFraud'],\n",
    "                                                                non_fraud.loc[:,non_fraud.columns=='isFraud'],\n",
    "                                                                train_size=train_pct,test_size=validate_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standard scaling to rescale the datasets' independent features\n",
    "standard_ae = StandardScaler()\n",
    "standard_x_train_ae = standard_ae.fit_transform(x_train_ae)\n",
    "standard_x_test_ae = standard_ae.transform(x_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using normalized scaling to rescale the datasets' independent features\n",
    "minmax_ae = MinMaxScaler()\n",
    "minmax_x_train_ae = minmax_ae.fit_transform(x_train_ae)\n",
    "minamx_x_test_ae = minmax_ae.transform(x_test_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network with Standardized Imbalanced Big Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_ann = Sequential()\n",
    "\n",
    "imbalanced_ann.add(InputLayer(input_shape=(11,)))\n",
    "imbalanced_ann.add(Dense(64,activation='relu'))\n",
    "imbalanced_ann.add(Dropout(0.2))\n",
    "imbalanced_ann.add(Dense(32,activation='relu'))\n",
    "imbalanced_ann.add(Dropout(0.1))\n",
    "imbalanced_ann.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,881\n",
      "Trainable params: 2,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imbalanced_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_ann.compile(loss=loss_function,optimizer=optimization_function,metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"models/imbalanced-ann-weights-improvement-{epoch:02d}-{val_\"+metric+\":.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_imbalanced_ann = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4072076 samples, validate on 1018020 samples\n",
      "Epoch 1/5\n",
      "4071904/4072076 [============================>.] - ETA: 0s - loss: 0.0203 - binary_accuracy: 0.9976\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.99905, saving model to models/imbalanced-ann-weights-improvement-01-1.00.hdf5\n",
      "4072076/4072076 [==============================] - 464s 114us/sample - loss: 0.0203 - binary_accuracy: 0.9976 - val_loss: 0.0134 - val_binary_accuracy: 0.9991\n",
      "Epoch 2/5\n",
      "4072064/4072076 [============================>.] - ETA: 0s - loss: 0.0207 - binary_accuracy: 0.9978\n",
      "Epoch 00002: val_binary_accuracy improved from 0.99905 to 0.99911, saving model to models/imbalanced-ann-weights-improvement-02-1.00.hdf5\n",
      "4072076/4072076 [==============================] - 453s 111us/sample - loss: 0.0207 - binary_accuracy: 0.9978 - val_loss: 0.0144 - val_binary_accuracy: 0.9991\n",
      "Epoch 3/5\n",
      "4071968/4072076 [============================>.] - ETA: 0s - loss: 0.0226 - binary_accuracy: 0.9978- ETA: 0s - loss: 0.0226 - binary_accuracy: 0.\n",
      "Epoch 00003: val_binary_accuracy improved from 0.99911 to 0.99921, saving model to models/imbalanced-ann-weights-improvement-03-1.00.hdf5\n",
      "4072076/4072076 [==============================] - 491s 121us/sample - loss: 0.0227 - binary_accuracy: 0.9978 - val_loss: 0.0118 - val_binary_accuracy: 0.9992\n",
      "Epoch 4/5\n",
      "4072064/4072076 [============================>.] - ETA: 0s - loss: 0.0237 - binary_accuracy: 0.9978\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.99921\n",
      "4072076/4072076 [==============================] - 502s 123us/sample - loss: 0.0237 - binary_accuracy: 0.9978 - val_loss: 0.0055 - val_binary_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "4071968/4072076 [============================>.] - ETA: 0s - loss: 0.0259 - binary_accuracy: 0.9979\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.99921\n",
      "4072076/4072076 [==============================] - 515s 126us/sample - loss: 0.0259 - binary_accuracy: 0.9979 - val_loss: 0.0063 - val_binary_accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "standard_imbalaned_ann_fit = imbalanced_ann.fit(standard_x_train,y_train,callbacks=callbacks_list_imbalanced_ann,\n",
    "                                                batch_size=batch_bin,epochs=num_epochs,validation_split=validate_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_imbalanced_y_pred = imbalanced_ann.predict_classes(standard_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of true positives: 30.27%\n",
      "Percent of false negatives: 69.73%\n",
      "Percent of true negatives: 100.00%\n",
      "Percent of false positives: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Fraud</th>\n",
       "      <th>Pred Non-Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fraud</th>\n",
       "      <td>490</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Non-Fraud</th>\n",
       "      <td>1</td>\n",
       "      <td>1270904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Pred Fraud  Pred Non-Fraud\n",
       "Actual Fraud             490            1129\n",
       "Actual Non-Fraud           1         1270904"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_confusion_matrix(y_test,standardized_imbalanced_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save standardized imbalanced_ann model\n",
    "# serialize model to JSON\n",
    "with open(\"models/standardized_imbalaned_ann_fraud_detector.json\", \"w\") as json_file:\n",
    "    json_file.write(imbalanced_ann.to_json())\n",
    "# serialize weights to HDF5\n",
    "imbalanced_ann.save_weights(\"models/standardized_imbalaned_ann_fraud_detector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network with Normalized Imbalanced Big Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"models/imbalanced-minmax-ann-weights-improvement-{epoch:02d}-{val_\"+metric+\":.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_imbalanced_ann = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4072076 samples, validate on 1018020 samples\n",
      "Epoch 1/5\n",
      "4071904/4072076 [============================>.] - ETA: 0s - loss: 0.0122 - binary_accuracy: 0.9986\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.99871, saving model to models/imbalanced-minmax-ann-weights-improvement-01-1.00.hdf5\n",
      "4072076/4072076 [==============================] - 547s 134us/sample - loss: 0.0122 - binary_accuracy: 0.9986 - val_loss: 0.0084 - val_binary_accuracy: 0.9987\n",
      "Epoch 2/5\n",
      "4071840/4072076 [============================>.] - ETA: 0s - loss: 0.0123 - binary_accuracy: 0.9986\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.99871\n",
      "4072076/4072076 [==============================] - 487s 120us/sample - loss: 0.0123 - binary_accuracy: 0.9986 - val_loss: 0.0166 - val_binary_accuracy: 0.9987\n",
      "Epoch 3/5\n",
      "4071680/4072076 [============================>.] - ETA: 0s - loss: 0.0127 - binary_accuracy: 0.9985\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.99871\n",
      "4072076/4072076 [==============================] - 475s 117us/sample - loss: 0.0127 - binary_accuracy: 0.9985 - val_loss: 0.0112 - val_binary_accuracy: 0.9987\n",
      "Epoch 4/5\n",
      "4071840/4072076 [============================>.] - ETA: 0s - loss: 0.0131 - binary_accuracy: 0.9985\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.99871\n",
      "4072076/4072076 [==============================] - 444s 109us/sample - loss: 0.0131 - binary_accuracy: 0.9985 - val_loss: 0.0144 - val_binary_accuracy: 0.9987\n",
      "Epoch 5/5\n",
      "4071872/4072076 [============================>.] - ETA: 0s - loss: 0.0134 - binary_accuracy: 0.9984\n",
      "Epoch 00005: val_binary_accuracy improved from 0.99871 to 0.99872, saving model to models/imbalanced-minmax-ann-weights-improvement-05-1.00.hdf5\n",
      "4072076/4072076 [==============================] - 447s 110us/sample - loss: 0.0134 - binary_accuracy: 0.9984 - val_loss: 0.0109 - val_binary_accuracy: 0.9987\n"
     ]
    }
   ],
   "source": [
    "minmax_imbalanced_ann = clone_model(imbalanced_ann)\n",
    "minmax_imbalanced_ann.compile(loss=loss_function,optimizer=optimization_function,metrics=[metric])\n",
    "minamx_imbalaned_ann_fit = minmax_imbalanced_ann.fit(minmax_x_train,y_train,callbacks=callbacks_list_imbalanced_ann,\n",
    "                                                     batch_size=batch_bin,epochs=num_epochs,validation_split=validate_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_imbalanced_y_pred = minmax_imbalanced_ann.predict_classes(minmax_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of true positives: 0.31%\n",
      "Percent of false negatives: 99.69%\n",
      "Percent of true negatives: 100.00%\n",
      "Percent of false positives: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Fraud</th>\n",
       "      <th>Pred Non-Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fraud</th>\n",
       "      <td>5</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Non-Fraud</th>\n",
       "      <td>1</td>\n",
       "      <td>1270904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Pred Fraud  Pred Non-Fraud\n",
       "Actual Fraud               5            1614\n",
       "Actual Non-Fraud           1         1270904"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_confusion_matrix(y_test,normalized_imbalanced_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nornalized imbalanced_ann model\n",
    "# serialize model to JSON\n",
    "with open(\"models/normalized_imbalaned_ann_fraud_detector.json\", \"w\") as json_file:\n",
    "    json_file.write(minmax_imbalanced_ann.to_json())\n",
    "# serialize weights to HDF5\n",
    "minmax_imbalanced_ann.save_weights(\"models/normalized_imbalaned_ann_fraud_detector.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward with Randomly Balanced Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ann = Sequential()\n",
    "\n",
    "balanced_ann.add(InputLayer(input_shape=(11,)))\n",
    "balanced_ann.add(Dense(64,activation='relu'))\n",
    "balanced_ann.add(Dropout(0.2))\n",
    "balanced_ann.add(Dense(32,activation='relu'))\n",
    "balanced_ann.add(Dropout(0.1))\n",
    "balanced_ann.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,881\n",
      "Trainable params: 2,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "balanced_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ann.compile(loss=loss_function,optimizer=optimization_function,metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"models/balanced-ann-weights-improvement-{epoch:02d}-{val_\"+metric+\":.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_balanced_ann = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10512 samples, validate on 2628 samples\n",
      "Epoch 1/5\n",
      "10432/10512 [============================>.] - ETA: 0s - loss: 2.2804 - binary_accuracy: 0.4919\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.51560, saving model to models/balanced-ann-weights-improvement-01-0.52.hdf5\n",
      "10512/10512 [==============================] - 7s 648us/sample - loss: 2.2746 - binary_accuracy: 0.4914 - val_loss: 1.7996 - val_binary_accuracy: 0.5156\n",
      "Epoch 2/5\n",
      "10272/10512 [============================>.] - ETA: 0s - loss: 1.7420 - binary_accuracy: 0.4978\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.51560\n",
      "10512/10512 [==============================] - 2s 201us/sample - loss: 1.7293 - binary_accuracy: 0.4972 - val_loss: 1.8970 - val_binary_accuracy: 0.5156\n",
      "Epoch 3/5\n",
      "10048/10512 [===========================>..] - ETA: 0s - loss: 1.4591 - binary_accuracy: 0.5028\n",
      "Epoch 00003: val_binary_accuracy improved from 0.51560 to 0.51598, saving model to models/balanced-ann-weights-improvement-03-0.52.hdf5\n",
      "10512/10512 [==============================] - 1s 126us/sample - loss: 1.4575 - binary_accuracy: 0.5031 - val_loss: 0.8896 - val_binary_accuracy: 0.5160\n",
      "Epoch 4/5\n",
      "10048/10512 [===========================>..] - ETA: 0s - loss: 1.2822 - binary_accuracy: 0.5020\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.51598\n",
      "10512/10512 [==============================] - 1s 117us/sample - loss: 1.2756 - binary_accuracy: 0.5012 - val_loss: 1.6046 - val_binary_accuracy: 0.5160\n",
      "Epoch 5/5\n",
      "10144/10512 [===========================>..] - ETA: 0s - loss: 1.1588 - binary_accuracy: 0.4973\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.51598\n",
      "10512/10512 [==============================] - 2s 173us/sample - loss: 1.1491 - binary_accuracy: 0.4970 - val_loss: 1.3048 - val_binary_accuracy: 0.5145\n"
     ]
    }
   ],
   "source": [
    "standard_balaned_ann_fit = balanced_ann.fit(rand_standard_x_train,rand_y_train,\n",
    "                                            callbacks=callbacks_list_balanced_ann,\n",
    "                                            batch_size=batch_bin,epochs=num_epochs,\n",
    "                                            validation_split=validate_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_balanced_y_pred = balanced_ann.predict_classes(rand_standard_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of true positives: 98.72%\n",
      "Percent of false negatives: 1.28%\n",
      "Percent of true negatives: 1.45%\n",
      "Percent of false positives: 98.55%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Fraud</th>\n",
       "      <th>Pred Non-Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Fraud</th>\n",
       "      <td>1615</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Non-Fraud</th>\n",
       "      <td>1626</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Pred Fraud  Pred Non-Fraud\n",
       "Actual Fraud            1615              21\n",
       "Actual Non-Fraud        1626              24"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_confusion_matrix(rand_y_test,standardized_balanced_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward with SMOTE Big Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_ann = Sequential()\n",
    "\n",
    "smote_ann.add(InputLayer(input_shape=(11,)))\n",
    "smote_ann.add(Dense(64,activation='relu'))\n",
    "smote_ann.add(Dropout(0.2))\n",
    "smote_ann.add(Dense(32,activation='relu'))\n",
    "smote_ann.add(Dropout(0.1))\n",
    "smote_ann.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,881\n",
      "Trainable params: 2,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "smote_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_ann.compile(loss=loss_function,optimizer=optimization_function,metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"models/smote-balanced-ann-weights-improvement-{epoch:02d}-{val_\"+metric+\":.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_'+metric, verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list_smote_balanced_ann = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandardized_smote_fit=smote_ann.fit(standard_x_train_sm,standard_y_train_sm,\n",
    "                                    callbacks=callbacks_list_smote_balanced_ann,\n",
    "                                    batch_size=batch_bin,epochs=num_epochs,validation_split=validate_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_smote_y_pred = smote_ann.predict_classes(standard_x_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(standard_y_test_sm,standardized_smote_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nornalized imbalanced_ann model\n",
    "# serialize model to JSON\n",
    "with open(\"models/standardized_smote_balaned_ann_fraud_detector.json\", \"w\") as json_file:\n",
    "    json_file.write(smote_ann.to_json())\n",
    "# serialize weights to HDF5\n",
    "smote_ann.save_weights(\"models/standardized_smote_balaned_ann_fraud_detector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Non-Fraud</th>\n",
       "      <th>Pred Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Non-Fraud</th>\n",
       "      <td>1251919</td>\n",
       "      <td>18944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Fraud</th>\n",
       "      <td>30</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Pred Non-Fraud  Pred Fraud\n",
       "Actual Non-Fraud         1251919       18944\n",
       "Actual Fraud                  30        1631"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main idea : we utilize the replication function of autoencoder nueral network. We train the model only by non-fraud dataset, so that the model can well replicate the features in non-fraud dataset but fails to give good replication for fraud dataset. If we have new unknown data to input to the model, it is classifed as fruad if it return high error, vice versa.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up autoencoder model\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(InputLayer(input_shape=(11,)))\n",
    "model1.add(Dense(8,activation='relu'))\n",
    "model1.add(Dense(4,activation='relu'))\n",
    "model1.add(Dense(8,activation='relu'))\n",
    "model1.add(Dense(11,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 11)                99        \n",
      "=================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paramater of the model\n",
    "model1.compile(loss='mae',optimizer='RMSProp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset, one contains only non-fraud data and one contains only fraud data\n",
    "non_fraud = data2[data2['isFraud']==0]\n",
    "fraud = data2[data2['isFraud']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we only use non-fraud data to train the model, we split training set and test set from non-fraud data set\n",
    "x_train_ae, x_test_ae, y_train_ae, y_test_ae = train_test_split(non_fraud.loc[:,non_fraud.columns!='isFraud'],\n",
    "                                                    non_fraud.loc[:,non_fraud.columns=='isFraud'],\n",
    "                                                    test_size=0.2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the value\n",
    "standard = StandardScaler()\n",
    "standard_x_train_ae = standard.fit_transform(x_train_ae)\n",
    "standard_x_test_ae = standard.transform(x_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4066820 samples, validate on 1016705 samples\n",
      "Epoch 1/5\n",
      "4066820/4066820 [==============================] - 176s 43us/step - loss: 0.1101 - val_loss: 0.0879\n",
      "Epoch 2/5\n",
      "4066820/4066820 [==============================] - 175s 43us/step - loss: 0.0837 - val_loss: 0.0812\n",
      "Epoch 3/5\n",
      "4066820/4066820 [==============================] - 175s 43us/step - loss: 0.0789 - val_loss: 0.0807\n",
      "Epoch 4/5\n",
      "4066820/4066820 [==============================] - 177s 43us/step - loss: 0.0766 - val_loss: 0.0709\n",
      "Epoch 5/5\n",
      "4066820/4066820 [==============================] - 174s 43us/step - loss: 0.0690 - val_loss: 0.0662\n"
     ]
    }
   ],
   "source": [
    "# train model (note: we are trying to replicate the features of non-fraud dataset, so both explanatory and target variables are standard_x_train_ae)\n",
    "standardfit = model1.fit(standard_x_train_ae,standard_x_train_ae, batch_size=100, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270882/1270882 [==============================] - 52s 41us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance of replicating non-fraud dataset by test set\n",
    "eva = model1.evaluate(standard_x_test_ae,standard_x_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0661094989341098"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_fraud = standard.fit_transform(fraud.loc[:,fraud.columns!='isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8213/8213 [==============================] - 0s 51us/step\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performace of replicating fraud dataset\n",
    "fraud_test=model1.evaluate(standard_fraud, standard_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4029295332652707"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conclusion: the model is good, the error for fraud dataset is significantly higher than non-fraud dataset. fraud_test>>>eva. See the report for more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
